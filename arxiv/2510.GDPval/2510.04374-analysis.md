---
title: "GDPval Analysis"
source: ./2510.04374.md
arxiv_id: "2510.04374"
paper_type: Benchmark
analyzed_date: 2026-02-06
details_folder: ./2510.04374-details/
---

# GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks

> **Paper**: [2510.04374](./2510.04374.md) | **Published**: 2025-10-05
> **Authors**: Tejal Patwardhan, Rachel Dias, Elizabeth Proehl, et al. (OpenAI)

---

## 1. Overview

### 논문 요약

AI 모델의 경제적 영향을 측정하는 기존 방법들(채택률, 사용 패턴, GDP 기여도)은 기술 확산에 수년이 걸리는 현실을 감안하면 **후행 지표(lagging indicator)**에 불과하다. GDPval은 이 문제를 해결하기 위해 AI 모델의 역량을 직접 측정하는 **선행 지표(leading indicator)** 접근법을 제안한다. 미국 GDP 상위 9개 산업 부문, 44개 직업군에서 평균 14년 경력의 전문가들이 실제 업무를 기반으로 1,320개 태스크를 구축하였다.

GDPval의 핵심 차별점은 현실성(realism), 대표적 범위(representative breadth), 컴퓨터 활용 및 멀티모달리티, 주관성(subjectivity), 상한 없는 평가(no upper limit), 장기 호라이즌 난이도(평균 7시간)에 있다. 기존 학술 시험 스타일 벤치마크(MMLU, GPQA)나 특정 도메인 벤치마크(SWE-Lancer)와 달리, 실제 업무 산출물(deliverable)의 품질을 전문가 블라인드 비교(pairwise comparison)로 평가한다.

주요 결과로, Claude Opus 4.1이 47.6% 승률로 최고 성능을 보이며 인간 전문가에 근접하고 있음을 확인하였다. OpenAI 프론티어 모델들의 성능은 시간에 따라 대략 선형적으로 증가하고 있으며, 추론 노력(reasoning effort) 증가, 프롬프트 튜닝, 스캐폴딩이 성능을 향상시킨다. 또한 220개 골드 서브셋과 실험적 자동 채점 서비스를 evals.openai.com에서 오픈소스로 공개하였다.

이 벤치마크는 AI의 경제적 영향을 **역량 기반(capability-based)**으로 추적할 수 있는 최초의 체계적 프레임워크를 제공한다. 단순 정확도가 아닌 전문가 대비 승률이라는 평가 방식은 포화 없이 지속적 평가가 가능하며, 속도/비용 분석을 통해 실제 도입 시나리오별 ROI를 정량화한 것은 실무적으로도 의미 있다.

---

## 2. Core Section

### TL;DR
> [Extended TL;DR](./2510.04374-details/tldr.md)

**One-liner**: 미국 GDP 상위 9개 부문 44개 직업군의 실제 업무 1,320개를 전문가 블라인드 비교로 평가하는 최초의 경제적 가치 기반 AI 벤치마크

**Key Numbers**:
- 태스크: 1,320개 (full set), 220개 (gold subset)
- 최고 승률: Claude Opus 4.1 47.6%
- 산업 부문: 9개, 직업군: 44개
- 연간 총 보상: $3T (대상 직업군)
- 평균 태스크 완료 시간: 7시간 (전문가)

### Core Contributions
> [Contributions Deep Analysis](./2510.04374-details/contributions.md)

| 기여 | 중요도 | 설명 |
|------|--------|------|
| 경제적 가치 기반 벤치마크 | ★★★★★ | GDP 부문별 체계적 직업 선정 + 전문가 기반 태스크 |
| 전문가 블라인드 비교 평가 | ★★★★★ | 포화 없는 승률 기반 지속적 평가 체계 |
| 속도/비용 분석 프레임워크 | ★★★★☆ | Try-n-times-then-fix 시나리오별 ROI 정량화 |
| 실험적 자동 채점기 | ★★★★☆ | 인간 평가자 대비 5% 이내 일치율 (66% vs 71%) |
| 모델 강약점 클러스터링 | ★★★☆☆ | 전문가 판단 근거 분석을 통한 실패 유형 분류 |

### Key vs Non-Key Sections
> [Section Reading Guide](./2510.04374-details/key-sections.md)

**Must Read**: Section 2 (태스크 생성), Section 3.1 (헤드라인 결과), Section 3.3 (모델 강약점)
**Recommended**: Section 3.2 (속도/비용), Section 3.4 (추론 노력 실험), Section 5 (한계)
**Optional**: Section 4 (오픈소싱), Appendix A.2 (추가 실험 결과)

---

## 3. Paper Type: Benchmark

### Classification

| 분류 | 상세 |
|------|------|
| **Primary Type** | Benchmark (태스크 + 평가 + 분석) |
| **Secondary Type** | Economic Impact Analysis |
| **Evaluation Target** | 프론티어 AI 모델의 실제 업무 수행 능력 |
| **Task Count** | 1,320 (full) / 220 (gold subset) |
| **Domains** | 9개 GDP 부문, 44개 직업군 |
| **Main Metrics** | 전문가 블라인드 비교 승률 (win rate) |

> 상세 방법론: [methodology.md](./2510.04374-details/methodology.md)

---

## 4. Visual Analysis

### Key Figures

**[Figure 1](./2510.04374.md#figure-1-example-gdpval-tasks-from-full-set)**: GDPval 태스크 예시
- 실제 업무 기반 태스크의 구체적 예시 제공
- 요청(request) + 참조 파일(reference files) + 산출물(deliverable) 구조

**[Figure 2](./2510.04374.md#figure-2-gdpval-includes-real-world-work-from-44-occupations)**: 44개 직업군 분포
- 9개 부문별 직업군과 태스크 수 시각화
- GDP 기여도 기반 체계적 선정 과정

**[Figure 5](./2510.04374.md#figure-5-on-human-pairwise-comparisons)**: 헤드라인 결과 (승률)
- Claude Opus 4.1이 47.6%로 최고 성능
- GPT-5 (39.0%), o3 (35.2%), Gemini 2.5 Pro, Grok 4 순
- 모델 산출물이 절반 이상의 태스크에서 전문가와 동등 이상

**[Figure 6](./2510.04374.md#figure-6-performance-of-openai-frontier-models)**: 시간에 따른 성능 향상
- OpenAI 프론티어 모델 성능의 대략 선형적 증가 추세
- GPT-4o → o4-mini → o3 → GPT-5

**[Figure 8](./2510.04374.md#figure-8-across-models)**: 모델별 실패 유형 분석
- 지시 따르기 실패가 모든 모델에서 가장 빈번한 패배 원인
- GPT-5는 포맷 오류가 주요 패배 원인, 지시 따르기는 최소
- Claude, Grok, Gemini는 지시 따르기 실패가 주된 원인

### Math Formulations

**속도/비용 분석 (Section A.2.1)**:

Try-1-time 시나리오:
$$\mathbb{E}[T_{1,i}] = M_{T,i} + R_{T,i} + (1 - w_i)H_{T,i} \tag{1}$$

Try-n-times 시나리오 (일반화):
$$\mathbb{E}[T_{n,i}] = (M_{T,i} + R_{T,i})\frac{1 - (1 - w_i)^n}{w_i} + (1 - w_i)^n H_{T,i} \tag{4}$$

- $H_T$: 인간 전문가 완료 시간 (평균 404분)
- $M_T$: 모델 완료 시간
- $R_T$: 인간 검토 시간 (평균 109분)
- $w_i$: 태스크 $i$에 대한 모델 승률

### Tables Interpretation

**[Table 2](./2510.04374.md#table-2-speed-and-cost-improvements)**: 속도/비용 개선 비율

| Model | Win rate | Speed (Try 1x) | Cost (Try nx) |
|-------|----------|-----------------|----------------|
| gpt-4o | 12.5% | 0.87x | 0.53x |
| o4-mini | 29.1% | 1.02x | 1.22x |
| o3 | 35.2% | 1.08x | 1.47x |
| gpt-5 | 39.0% | 1.12x | 1.63x |

**주요 발견**:
1. 승률 ~30% 이상부터 Try-1x 시나리오에서도 시간/비용 절감 시작
2. Try-nx에서 GPT-5는 비용 1.63배 절감 가능
3. 검토 시간을 포함하면 Naive ratio(수백 배)가 현실적 수준(1-2배)으로 급감

**실무적 의미**: 현재 프론티어 모델은 전문가 감독 하에 도입 시 소폭의 시간/비용 절감 가능. 승률이 지속 개선되면 ROI가 급격히 증가할 전망

---

## 5. Critique & Related Works

### Strengths

1. **경제적 근거 기반 설계**: GDP 부문별 직업 선정, O*NET 태스크 커버리지, 달러 가치 추정 등 경제학적 엄밀성
2. **현실적 태스크**: 평균 14년 경력 전문가의 실제 업무 기반, 멀티모달 파일 포맷 (CAD, PPT, XLSX 등) 활용
3. **포화 없는 평가**: 승률 기반으로 베이스라인을 점진적으로 강화 가능, 장기적 추적에 적합
4. **투명한 방법론**: 태스크 품질 파이프라인(평균 5회 리뷰), 자동 채점기 한계 명시, 비용 분석의 가정 명시

### Limitations

1. **데이터셋 규모**: 직업당 30개 태스크는 직업 내 태스크 다양성을 충분히 커버하기 어려움
2. **지식 노동 편향**: 디지털 업무만 포함, 수작업/물리적 노동, 대인 커뮤니케이션, 암묵지(tacit knowledge) 미반영
3. **일회성(one-shot) 설정**: 실제 업무의 반복적 상호작용, 맥락 파악 과정이 누락됨 (under-contextualized 실험에서 성능 하락 확인)
4. **채점 비용**: 전문가 비교 채점에 태스크당 평균 1시간 이상 소요, 대규모 확장 어려움
5. **자체 편향 우려**: OpenAI 벤치마크이나 Claude Opus 4.1이 최고 성능 → 객관성 강조에도 모델별 설정 차이 존재 가능

### 2026년 관점에서의 평가

**Still Valid**:
- 실제 업무 기반 평가의 필요성과 프레임워크 설계는 여전히 유효
- 승률 기반 지속적 평가 방법론은 후속 벤치마크의 표준이 될 수 있음

**Outdated**:
- 평가 대상 모델(GPT-4o, o3 등)은 이미 구세대
- 220개 골드 서브셋은 데이터 오염(contamination) 위험

**Missing**:
- 에이전트 프레임워크(multi-turn, tool use 체인) 활용 평가 미반영
- 협업 시나리오 (인간-AI 상호작용) 미포함
- 비영어권, 비미국 경제 맥락 부재

### Adoption Status
- [x] Easy to set up (evals.openai.com에서 자동 채점 가능)
- [ ] Widely used (2025년 10월 출시, 아직 초기)
- [ ] Clear leaderboard (공식 리더보드 미확인)
- [ ] Active maintenance (향후 버전 계획 명시)

### Related Works & Positioning

**선행 연구**:
- **SWE-Lancer** (Miserendino et al., 2025): 소프트웨어 엔지니어링 특화 프리랜서 벤치마크
- **GPQA** (Rein et al., 2023): 대학원 수준 학술 질문, 학술 시험 스타일
- **Humanity's Last Exam** (Phan et al., 2025): 최고 난이도 학술 문제

**경제적 영향 분석**:
- **Eloundou et al. (2023)**: GPTs의 노동시장 영향 잠재력 (태스크 기반 노출도)
- **Anthropic Economic Index** (Tamkin et al., 2024): 실제 AI 사용 패턴 분석
- **Clio** (Tamkin et al., 2024): 프라이버시 보존 AI 사용 인사이트

**Position in Literature**:
```
[학술 시험 스타일]          [실제 업무 기반]
    MMLU, GPQA                 GDPval
         ↓                         ↓
    HLE                     SWE-Lancer (SW only)
                                    ↓
                         Future: 상호작용형 GDPval v2
```

---

## Navigation

### Detail Files
- [Extended TL;DR](./2510.04374-details/tldr.md)
- [Core Contributions](./2510.04374-details/contributions.md)
- [Key Sections Guide](./2510.04374-details/key-sections.md)
- [Methodology Detail](./2510.04374-details/methodology.md)

### External Links
- [Original Paper](./2510.04374.md)
- [arXiv](https://arxiv.org/abs/2510.04374)
- [evals.openai.com](https://evals.openai.com)
