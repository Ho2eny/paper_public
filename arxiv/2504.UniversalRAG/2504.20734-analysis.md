---
title: "UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities - Analysis"
arxiv_id: "2504.20734"
type: "analysis"
paper_type: "method"
analyzed_date: "2026-02-06"
source: "./2504.20734.md"
details: "./2504.20734-details/"
---

# UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities - Analysis

## 1. Overview

기존 RAG 시스템은 텍스트, 이미지, 비디오 등 단일 모달리티 코퍼스에서만 검색하도록 설계되어 있으며, 현실 세계의 다양한 질의 유형에 유연하게 대응하지 못한다. 예컨대 "미시간 병사 기념비에 동상이 몇 개인가?"라는 질문은 텍스트와 이미지를 동시에 참조해야 정확한 답을 낼 수 있지만, 기존 단일 모달리티 RAG는 이 중 하나만 검색한다. 이 논문은 이러한 근본적 한계를 정면으로 다루며, 이질적인 멀티모달 코퍼스를 통합적으로 활용하는 "one-for-all" RAG 프레임워크를 제안한다.

저자들이 제안하는 **UniversalRAG**의 핵심 통찰은 모든 모달리티를 하나의 통합 임베딩 공간에 밀어넣는 방식이 *modality gap* 문제로 인해 근본적으로 제한된다는 것이다. t-SNE 시각화와 이론적 분석을 통해, 통합 공간에서는 텍스트 쿼리가 의미적 유사성이 아닌 모달리티 유사성에 의해 텍스트 문서만 검색하는 편향이 발생함을 보인다. 이를 해결하기 위해 **modality-aware routing**을 도입하여, 쿼리를 먼저 적합한 모달리티별 코퍼스로 라우팅한 후 해당 코퍼스 내에서 검색을 수행한다. 더 나아가, 동일 모달리티 내에서도 문단 vs 문서, 클립 vs 전체 비디오 등 **granularity-aware retrieval**을 통해 쿼리 복잡도에 맞는 검색 단위를 선택한다.

10개 벤치마크(MMLU, NQ, HotpotQA, HybridQA, MRAG-Bench, WebQA, InfoSeek, LVBench, VideoRAG-Wiki/Synth)에서의 실험 결과, UniversalRAG는 3개의 서로 다른 LVLM(Qwen3-VL-8B, InternVL3.5-8B, Molmo2-4B)에서 평균적으로 모든 베이스라인을 일관되게 능가한다. 특히 학습 기반 라우터(Qwen3-VL-2B)는 95.28%의 모달리티 정확도를 달성하며, 통합 임베딩 베이스라인 대비 검색 recall에서 큰 격차를 보인다. Out-of-domain 시나리오에서도 훈련-free 라우터가 강건한 일반화를 보이며, 앙상블 전략으로 둘의 상보적 강점을 결합한다.

이 연구는 RAG 분야에서 "어떤 코퍼스에서 검색할 것인가"라는 라우팅 문제를 체계적으로 정립한 첫 연구로, 모달리티와 세분화도를 동시에 고려하는 프레임워크를 제안했다는 점에서 의의가 크다. 다만 라우팅 라벨이 데이터셋의 귀납적 편향에서 자동 생성되었다는 점과, 코퍼스가 벤치마크별로 구성되어 현실적 대규모 통합 코퍼스 환경과 차이가 있다는 점은 후속 연구 과제로 남는다.

---

## 2. Core Section

### TL;DR

> UniversalRAG는 modality-aware routing으로 쿼리를 텍스트/이미지/비디오/테이블 등 최적 코퍼스로 동적 라우팅하고, granularity-aware retrieval로 문단/문서/클립/비디오 등 적합한 검색 단위를 선택하여, 통합 임베딩의 modality gap 문제를 회피하면서 10개 벤치마크에서 모든 베이스라인을 능가하는 one-for-all RAG 프레임워크이다.

→ 상세: [tldr.md](./2504.20734-details/tldr.md)

### Core Contributions

1. **Modality-Aware Routing**: 통합 임베딩 공간의 modality gap을 이론적으로 분석하고, 쿼리를 모달리티별 코퍼스로 동적 라우팅하는 메커니즘 제안 → 통합 임베딩 대비 모달리티 정확도 95.28% vs 25-36%
2. **Granularity-Aware Retrieval**: 모달리티뿐 아니라 검색 단위(문단/문서, 클립/비디오)까지 쿼리별로 선택하는 확장 → 세분화도 증가 시 일관된 성능 향상 (HotpotQA EM +1.5, LVBench Acc +0.93)
3. **Training-free 및 Training-based 라우터**: 프롬프트 기반 라우터(GPT-5, Qwen3-VL-8B)와 학습 기반 라우터(Qwen3-VL-2B, InternVL3.5-1B, T5Gemma 2 270M)를 모두 구현하여, in-domain 정확도와 OOD 일반화 간 trade-off 분석 및 앙상블 전략 제시
4. **10개 벤치마크 포괄 평가**: 텍스트, 이미지, 테이블, 비디오를 아우르는 종합 벤치마크에서 3개 LVLM으로 검증 → 실용적 범용 RAG의 가능성 입증

→ 상세: [contributions.md](./2504.20734-details/contributions.md)

### Key vs Non-Key Sections

| Priority | Sections | Reason |
|----------|----------|--------|
| ⭐⭐⭐ Must Read | 2.2 UniversalRAG, 3.2 Results & Analyses, Table 1, Figure 3 | 핵심 메커니즘과 주요 정량 결과 |
| ⭐⭐ Important | 2.3 Router Implementation, Table 5 (OOD), Figures 4-6 | 라우터 설계 선택과 OOD 일반화 분석 |
| ⭐ Reference | Appendix C (Theoretical), Appendix D (Additional Results) | 이론적 증명과 추가 LVLM 결과 |
| Skip | Appendix F (Case Studies), Figures 8-11 (Prompts) | 정성적 예시와 프롬프트 템플릿 |

→ 상세: [key-sections.md](./2504.20734-details/key-sections.md)

---

## 3. Paper Type

**Type**: Method

| Aspect | Value |
|--------|-------|
| **Problem** | 단일 모달리티/세분화도 RAG의 한계 + 통합 임베딩 공간의 modality gap |
| **Approach** | 모달리티-인식 라우팅 → 모달리티별 검색 → 세분화도 인식 검색 → LVLM 생성 |
| **Key Technique** | 쿼리 라우터(training-based: LoRA fine-tuned classifier, training-free: few-shot prompting) |
| **Main Result** | 10개 벤치마크 평균 42.40 (Qwen3-VL-2B router), 모든 베이스라인 능가 |

→ 상세 방법론: [methodology.md](./2504.20734-details/methodology.md)

---

## 4. Visual Analysis

### Key Figures

#### Figure 1: UniversalRAG Conceptual Comparison

![Figure 1](resources/figure_1.png)

**구성 요소**:
- **좌측 (기존 RAG)**: 각 RAG가 단일 모달리티 코퍼스만 검색 (TextRAG → 텍스트, ImageRAG → 이미지, VideoRAG → 비디오)
- **중앙 (통합 임베딩)**: 모든 코퍼스를 하나의 임베딩 공간에 통합하지만 modality gap으로 편향 발생
- **우측 (UniversalRAG)**: 라우터가 쿼리를 분석하여 적합한 모달리티+세분화도 코퍼스로 동적 라우팅

**핵심 통찰**:
- 기존 접근은 "하나의 모달리티만" 또는 "모두 섞기"의 양극단. UniversalRAG는 "선택적 라우팅"이라는 중간 전략으로 두 극단의 한계를 동시에 해결.

**Source**: [Section 1](./2504.20734.md#1-introduction)

---

#### Figure 2: Modality Gap in Unified Embedding Space

![Figure 2](resources/figure_2.png)

**핵심 통찰**:
- t-SNE 시각화에서 텍스트, 이미지, 비디오 임베딩이 의미가 아닌 모달리티 기준으로 클러스터링됨
- 이는 통합 임베딩 기반 검색이 실패하는 근본 원인. Proposition 1의 실험적 증거.

**Source**: [Section 1](./2504.20734.md#1-introduction)

---

#### Figure 3: RAG Methods Comparison Across LVLMs

![Figure 3](resources/figure_3.png)

**핵심 통찰**:
- 3개 LVLM(Qwen3-VL-8B, InternVL3.5-8B, Molmo2-4B) 모두에서 UniversalRAG가 일관되게 최고 성능
- 통합 임베딩 방법들(UniRAG, GME, PE_core, VLM2Vec-V2)은 Naive보다도 낮은 경우가 있어, modality gap의 심각성을 재확인

---

### Math Formulations

#### Proposition 1: Modality-Aware Routing의 이론적 우위

$$s(\mathbf{q}, \mathbf{c}) = \alpha \cdot \mathbf{1}\{m(\mathbf{q}) = m(\mathbf{c})\} + \beta \cdot r(\mathbf{q}, \mathbf{c}) + \varepsilon$$

**직관적 설명**: 통합 임베딩 공간에서의 유사도는 "모달리티 일치 보너스 $\alpha$" + "실제 의미 유사도 $\beta r$" + "노이즈 $\varepsilon$"로 분해된다. $\alpha$가 충분히 크면(modality gap이 심하면), 의미적으로 관련 있는 다른 모달리티 항목이 같은 모달리티의 무관한 항목보다 순위가 밀린다.

**예시**: 텍스트 쿼리 "What does the Eiffel Tower look like?"에 대해 통합 공간에서는 에펠탑 이미지보다 "Eiffel Tower history"라는 텍스트 문서가 $\alpha$만큼 유사도가 높아져 이미지가 검색되지 않음.

**Source**: [Section 2.2](./2504.20734.md#22-universalrag)

#### Routing Function

$$\mathcal{R}: \mathcal{Q} \to \{\varnothing\} \cup \mathcal{P}\left(\bigcup_{m \in M} \{m\} \times G_m\right)$$

**직관적 설명**: 라우팅 함수는 쿼리를 "검색 불필요($\varnothing$)" 또는 "모달리티-세분화도 쌍의 집합"으로 매핑. 쿼리에 따라 여러 모달리티를 동시에 선택(cross-modal retrieval)할 수 있다.

---

### Tables Interpretation

#### Table 1: Main Results (Qwen3-VL-8B)

**주요 발견**:
1. **Unimodal RAG의 한계**: ParagraphRAG는 NQ에서 강하지만(EM 39.25) MRAG에서 약하고(46.71), ImageRAG는 그 반대. 어떤 단일 모달리티도 모든 벤치마크에서 최적이 아님.
2. **통합 임베딩의 실패**: UniRAG(32.93), GME(33.88) 등은 Naive(35.59)보다도 평균이 낮음. Modality gap으로 인해 잘못된 모달리티 검색이 오히려 성능을 저하시킴.
3. **UniversalRAG의 우위**: 학습 기반 라우터(Qwen3-VL-2B)가 42.40으로 Oracle(42.45)에 근접. 라우팅 정확도 95.28%가 이 결과의 핵심.
4. **Training-free vs Training-based**: Training-free(GPT-5: 39.26)가 Training-based(42.40) 대비 약 3점 낮지만, OOD에서는 역전됨(Table 5).

**트레이드오프**: 학습 기반 라우터는 in-domain에서 강하나 OOD에서 약하고, training-free는 그 반대. 앙상블이 최적의 밸런스.

**Source**: [Table 1](./2504.20734.md#table-1)

#### Table 5: In-Domain vs Out-of-Domain Generalization

**주요 발견**:
1. **OOD 역전 현상**: 학습 기반 라우터 Qwen3-VL-2B는 in-domain 95.81% → OOD 71.29%로 하락. Training-free GPT-5는 72.33% → 77.38%로 오히려 상승.
2. **앙상블의 효과**: Confidence-based 앙상블이 in-domain 96.02%, OOD 80.71%로 두 영역 모두에서 최고.

---

## 5. Critique & Related Works

### Expert Critique

#### Strengths

1. **문제 정의와 이론적 기반**: Modality gap을 Proposition 1로 형식화하고, 라우팅이 통합 임베딩보다 우월한 조건을 수학적으로 증명. t-SNE 시각화(Figures 2, 7)가 실험적 증거를 뒷받침하여 설득력이 높다.
2. **포괄적 실험 설계**: 7가지 모달리티/세분화도, 10개 벤치마크, 3개 LVLM, 12개 베이스라인이라는 체계적 평가. 단일 축에 치우치지 않는 다각도 검증.
3. **실용적 라우터 설계**: Training-free(프롬프트만으로)와 Training-based(270M 소형 모델로도 가능)를 모두 제공하여 다양한 배포 환경에 적용 가능. 특히 270M T5Gemma 라우터가 41.68점을 달성하여 경량 배포가 현실적.
4. **효율성 이점**: Figure 5에서 코퍼스 크기 증가 시 통합 임베딩 대비 sub-linear한 latency 증가. 대규모 실제 환경에서 실용적 이점.

#### Limitations

1. **벤치마크 종속 코퍼스**: 각 벤치마크에 맞춤 구성된 코퍼스(WebQA용 이미지 코퍼스, HybridQA용 테이블 코퍼스 등)를 사용. 실제 환경의 대규모 통합 코퍼스(수십억 규모)에서의 라우팅 정확도와 성능은 미검증.
2. **라우팅 라벨의 자동 생성**: Ground-truth 라우팅 라벨이 없어 데이터셋의 귀납적 편향(예: HotpotQA → Document, MRAG → Image)으로 자동 생성. 이는 쿼리가 실제로 어떤 모달리티가 최적인지의 진정한 라벨이 아닐 수 있음.
3. **Audio, 3D 등 미지원 모달리티**: 텍스트, 이미지, 비디오, 테이블만 다루며, 오디오나 3D 데이터 등은 고려하지 않음. "Universal"이라는 이름의 범위가 제한적.
4. **세분화도 단계의 제한**: 텍스트(문단/문서)와 비디오(클립/전체)에 대해 2단계만 실험. 더 세밀한 단계(문장, 섹션, 시퀀스 등)에 대한 검증이 부족. Table 4에서 4단계까지 시도하나 training-free 라우터에서만.
5. **Cross-modal 검색의 제한적 분석**: Table 2에서 cross-modal이 uni-modal보다 우월함을 보이나, HybridQA와 WebQA 2개 벤치마크에서만 실험. 어떤 쿼리가 cross-modal을 필요로 하는지에 대한 체계적 분석 부족.

#### Reproducibility

- [x] Code available (GitHub, project page 공개)
- [x] Data available (벤치마크 데이터 공개)
- [x] Clear hyperparameters (LoRA rank=32, lr=2e-5, threshold=0.8 등)
- [ ] Compute budget disclosed (GPU 종류 RTX Pro 6000 96GB만 언급, 총 훈련 시간 미공개)

#### 2026 Perspective

- **Still Valid**: Modality gap 문제와 모달리티-인식 라우팅의 필요성은 현재도 유효. 통합 임베딩 모델이 발전하고 있으나(GME, VLM2Vec-V2), 완전한 modality gap 해소는 달성되지 않음.
- **Evolving**: RAG-Anything(2025), HM-RAG(2025) 등 후속 연구가 텍스트 변환이나 계층적 에이전트로 다른 접근을 시도 중. UniversalRAG의 라우팅 기반 접근과의 비교가 필요.
- **Missing**: (1) Agentic RAG와의 통합 (쿼리 분해 후 각 하위 쿼리를 라우팅), (2) 실시간 코퍼스 업데이트 대응, (3) 사용자 피드백 기반 라우터 개선, (4) 대규모 통합 코퍼스에서의 검증.

### Related Works

1. **UniRAG** (Sharifymoghaddam et al., 2025) - 통합 임베딩 공간에서 멀티모달 검색을 시도한 직접적 선행 연구. UniversalRAG가 이의 한계(modality gap)를 극복하려 함. [NAACL 2025]
2. **RAG-Anything** (Guo et al., 2025) - 모든 모달리티를 텍스트로 변환 후 검색하는 대안적 접근. 전처리 비용과 모달리티 정보 손실이 trade-off. UniversalRAG와의 비교가 필요.
3. **VideoRAG** (Jeong et al., 2025) - 비디오 코퍼스에 특화된 RAG. UniversalRAG의 비디오 벤치마크와 코퍼스 구성에 직접 활용. [ACL 2025 Findings]
4. **Adaptive-RAG** (Jeong et al., 2024) - 쿼리 복잡도에 따른 적응적 검색 전략의 선행 연구. 모달리티가 아닌 검색 전략 수준의 적응이지만, 동적 라우팅이라는 핵심 아이디어를 공유. [NAACL 2024]
5. **Dense X Retrieval** (Chen et al., 2024) - 검색 세분화도에 대한 체계적 분석. UniversalRAG의 granularity-aware 설계의 이론적 동기. [EMNLP 2024]

---

## Navigation

- **Source**: [원본 논문](./2504.20734.md)
- **Details**:
  - [TL;DR 상세](./2504.20734-details/tldr.md)
  - [Contributions 상세](./2504.20734-details/contributions.md)
  - [Key Sections 상세](./2504.20734-details/key-sections.md)
  - [Methodology 상세](./2504.20734-details/methodology.md)
