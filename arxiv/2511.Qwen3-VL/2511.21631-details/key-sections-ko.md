---
parent: ../2511.21631-analysis.md
source: ../2511.21631.md
language: "ko"
---

# 주요 vs 비주요 섹션 - 심층 분석

## ⭐⭐⭐ 필독 (이해에 필수)

### Section 2: 모델 아키텍처

**왜**: Qwen3-VL을 Qwen2.5-VL과 차별화하고 "현저히 더 강력한" 성능 주장을 정당화하는 세 가지 핵심 아키텍처 혁신을 포함한다.

**핵심 사항**:
1. **전체 아키텍처** ([Lines 133-147](../2511.21631.md#L133-L147)): Vision Encoder (SigLIP-2) → MLP Merger → LLM (Qwen3), 모델 크기 2B/4B/8B/32B (dense)와 30B-A3B/235B-A22B (MoE)
2. **Interleaved MRoPE** ([Section 2.1](../2511.21631.md#21-interleaved-mrope)): 청킹 대신 t/h/w 차원을 인터리빙하여 주파수 스펙트럼 불균형 해결
3. **DeepStack** ([Section 2.2](../2511.21631.md#22-deepstack)): 3개의 ViT 계층에서 시각적 토큰을 처음 3개의 LLM 계층에 주입—중요한 +2.2 MMMU 개선
4. **비디오 타임스탬프** ([Section 2.3](../2511.21631.md#23-video-timestamp)): 절대 시간 위치 ID를 "<3.0 seconds>"와 같은 명시적 텍스트 토큰으로 대체

**집중할 사항**:
- Figure 1 ([Line 138](../2511.21631.md#L138)): DeepStack 연결을 보여주는 시각적 다이어그램—다층 특징이 어디에 주입되는지 이해
- 각 혁신의 설계 근거—단순히 "무엇"이 아니라 "왜" (이전 작업의 구체적 한계 해결)

**건너뛰기**: 상세한 SigLIP-2 아키텍처 (외부 논문 [[77]](#ref-77)에서 참조됨)—동적 해상도 지원이 있는 대비 사전학습된 ViT라는 것만 알면 됨

**링크**: [Section 2](../2511.21631.md#2-model-architecture)

---

### Section 3.1: 학습 레시피

**왜**: 점진적 컨텍스트 확장 (8K → 256K)이 있는 4단계 사전학습 파이프라인을 설명—256K 컨텍스트 능력이 어떻게 달성되는지 이해하는 데 필수적이다.

**핵심 사항**:
1. **Stage 0 (정렬)** ([Lines 181-182](../2511.21631.md#L181-L182)): ViT와 LLM을 동결한 Merger 전용 학습 (67B 토큰, 8K 컨텍스트)—효율적인 초기 크로스 모달 브리징
2. **Stage 1 (멀티모달 사전학습)** ([Lines 183-185](../2511.21631.md#L183-L185)): ~1T 토큰 (VL + 텍스트 혼합)에서 8K 컨텍스트로 전체 파라미터 학습
3. **Stage 2 (장문맥)** ([Lines 187-188](../2511.21631.md#L187-L188)): 컨텍스트를 32K로 4배 확장, 텍스트 비율 증가 및 더 많은 비디오로 ~1T 토큰 학습
4. **Stage 3 (초장문맥)** ([Lines 189-190](../2511.21631.md#L189-L190)): 집중된 100B 토큰 (장시간 비디오/문서 강조)에서 256K 컨텍스트

**집중할 사항**:
- Table 1 ([Line 172](../2511.21631.md#L172)): 학습 설정 및 하이퍼파라미터—총 예산은 ~2.1T 토큰
- 제곱근 손실 정규화 ([Lines 124-125](../2511.21631.md#L124-L125)): 텍스트와 멀티모달 데이터의 균형을 맞추는 중요한 기법
- 점진적 컨텍스트 확장 전략—왜 처음부터 256K에서 학습하지 않는가?

**중요한 통찰**: Stage 3은 256K 적응을 위해 100B 토큰 (S1/S2 예산의 5%)만 사용—장문맥은 강력한 32K 기반 위에 구축된 특수 능력이며 전체 재학습이 필요하지 않음을 시사한다.

**링크**: [Section 3.1](../2511.21631.md#31-training-recipe)

---

### Section 5.12: 제거 실험

**왜**: 통제된 실험을 통해 각 설계 선택을 검증—실제로 중요한 것과 단순한 과장을 이해하는 데 필수적이다.

**핵심 사항**:
1. **Vision Encoder 선택** ([Section 5.12.1](../2511.21631.md#51221-vision-encoder)): SigLIP-2 SO-400M이 SigLIP-1 및 다른 ViT를 +3.5 MMMU로 능가
2. **DeepStack 기여** ([Section 5.12.2](../2511.21631.md#51222-deepstack), [Table 12](../2511.21631.md#table-12)): 다층 특징으로 +2.2 MMMU, +0.8 MMBench, +0.9 MathVista
3. **장문맥 능력** ([Section 5.12.3](../2511.21631.md#51223-needle-in-a-haystack)): 256K 토큰에서 Needle-in-a-Haystack 90% 이상 정확도

**집중할 사항**:
- Table 11 ([Vision Encoder 비교](../2511.21631.md#table-11)): SigLIP-2 SO-400M vs SigLIP-1 SO-400M vs Qwen2.5-ViT—SigLIP-2 선택을 정당화하는 +3.5 MMMU 개선
- Table 12 ([DeepStack 제거](../2511.21631.md#table-12)): 4개 벤치마크에서 DeepStack 기여 분리
- Figure 3 ([Needle-in-a-Haystack 히트맵](../2511.21631.md#figure-3)): 256K 컨텍스트 유지의 시각적 증거

**중요한 통찰**: 제거 실험은 flagship 235B 모델이 아닌 Qwen3-VL-8B에서 수행되었다—따라서 보고된 개선이 더 큰 스케일로 정확히 전이되지 않을 수 있다. 그러나 8B는 아키텍처 선택을 검증하기 위한 합리적인 프록시이다.

**링크**: [Section 5.12](../2511.21631.md#512-ablation-study)

---

## ⭐⭐ 중요 (복제를 위해 이해 필요)

### Section 4.2: Cold Start 데이터

**왜**: SFT 및 long-CoT 학습을 위한 데이터 큐레이션 및 필터링 프로토콜 상세—품질 관리 및 사후학습 복제 방법을 이해하는 데 중요하다.

**핵심 사항**:
1. **SFT 데이터 구성** ([Lines 310-311](../2511.21631.md#L310-L311)): 1.2M 샘플 (1/3 텍스트 전용, 2/3 멀티모달), 다국어 커버리지
2. **2단계 필터링** ([Lines 315-326](../2511.21631.md#L315-L326)):
   - 쿼리 필터링: 검증 불가능한 쿼리 폐기, 모호한 쿼리 수정
   - 응답 필터링: 규칙 기반 (반복, 형식) + 모델 기반 (Qwen2.5-VL 보상 모델)
3. **Long-CoT 데이터 큐레이션** ([Section 4.2.2](../2511.21631.md#422-long-cot-cold-start-data)): 난이도, 멀티모달 필요성, 품질에 대한 엄격한 필터링

**집중할 사항**:
- **멀티모달 필요성 필터링** ([Lines 337-338](../2511.21631.md#L337-L338)): Qwen3-30B-nothink가 시각적 입력 없이 해결할 수 있는 샘플 폐기—진정한 멀티모달 이해가 필요함을 보장
- **단계별 학습 전략** ([Line 313](../2511.21631.md#L313)): 첫 번째 에폭은 32K 컨텍스트, 두 번째 에폭은 256K (32K 샘플과 인터리브)—계산 효율성 트릭

**중요한 통찰**: 논문은 "쉬운" 샘플 (>90% 통과율)을 필터링하고 어려운 인스턴스를 유지하는 것을 강조—이는 RL 효과에 중요하다. 많은 실패한 RL 실험은 너무 쉬운 데이터로 학습하는 것이 원인일 가능성이 있다.

**링크**: [Section 4.2](../2511.21631.md#42-cold-start-data)

---

### Section 4.4: 강화학습

**왜**: 하이브리드 보상 시스템이 있는 2단계 RL 접근 (Reasoning RL + General RL)을 설명—SFT를 넘어서는 방법을 이해하는 데 중요하다.

**핵심 사항**:
1. **Reasoning RL** ([Section 4.4.1](../2511.21631.md#441-reasoning-reinforcement-learning)): 결정론적 검증이 있는 수학, 코딩, 논리, 그라운딩
   - 텍스트 및 멀티모달 작업에 걸쳐 30K 쿼리
   - 쉬운 쿼리 (>90% 통과율) 필터링
   - 정책 최적화를 위한 SAPO 알고리즘 [[21]](#ref-21)
2. **General RL** ([Section 4.4.2](../2511.21631.md#442-general-reinforcement-learning)): VQA, 캡셔닝, OCR, 지시 따르기
   - 하이브리드 보상 시스템: 규칙 기반 (형식 준수) + 모델 기반 (Qwen2.5-VL-72B 판단)
   - 목표 오류 수정 (언어 혼합, 반복)

**집중할 사항**:
- **보상 시스템 설계** ([Lines 359-360](../2511.21631.md#L359-L360), [Lines 374-377](../2511.21631.md#L374-L377)): 왜 하이브리드 보상인가 (정밀도를 위한 규칙 기반, 유연성을 위한 모델 기반)?
- **다중 작업 배치** ([Line 358](../2511.21631.md#L358)): 예비 실험을 통해 결정된 사전 정의된 작업 비율—RL 성공에 중요하지만 종종 간과됨

**중요한 통찰**: General RL은 **알려진 오류를 트리거하는** 프롬프트의 전용 데이터셋을 포함한다 (언어 혼합, 시계 인식 실수)—이는 단순한 성능 최적화가 아닌 사전 예방적 오류 수정이다.

**링크**: [Section 4.4](../2511.21631.md#44-reinforcement-learning)

---

### Section 4.5: Thinking with Images

**왜**: 도구 사용 (이미지 검색, 확대)이 있는 에이전트 워크플로우를 설명—수동적 Q&A를 넘어선 Qwen3-VL의 능력을 보여준다.

**핵심 사항**:
1. **2단계 학습** ([Lines 381-385](../2511.21631.md#L381-L385)):
   - Stage 1: 10K 그라운딩 예제 (think → act → analyze → answer)에서 Qwen2.5-VL-32B 에이전트 학습
   - Stage 2: Qwen3-VL 사후학습을 위해 120K 다회차 에이전트 상호작용으로 증류
2. **RL 보상 신호** ([Lines 387-392](../2511.21631.md#L387-L392)):
   - 답변 정확도 (Qwen3-32B가 정확성 판단)
   - 다회차 추론 (Qwen2.5-VL-72B가 일관된 추론 평가)
   - 도구 호출 보상 (복잡도에 따라 적응적 도구 사용 장려)

**집중할 사항**:
- **도구 호출 보상 근거** ([Lines 393-394](../2511.21631.md#L393-L394)): 이것이 없으면 모델은 작업 복잡도와 관계없이 단일 도구 호출로 퇴화—적절한 도구 사용을 명시적으로 보상하면 이를 방지
- **증류 전략**: 더 작고 특화된 에이전트 (Qwen2.5-VL-32B)를 사용하여 주 모델의 학습 데이터를 생성하는 것은 인간 주석의 효율적인 대안

**링크**: [Section 4.5](../2511.21631.md#45-thinking-with-images)

---

## ⭐ 권장 (맥락을 위해 훑어보기)

### Section 5.1-5.11: 벤치마크 평가

**왜**: 50개 이상의 벤치마크에 걸친 포괄적인 결과—능력을 이해하는 데 유용하지만 기술적 이해에 필수적이지 않음.

**읽기 전략**:
1. **Tables 2-4에 집중**: Flagship (235B-A22B), medium (32B, 30B-A3B), small (2B/4B/8B) 모델 비교
2. **확인할 주요 벤치마크**:
   - 일반 VQA ([Section 5.1](../2511.21631.md#51-general-visual-question-answering)): MMBench, RealWorldQA, MMStar
   - 멀티모달 추론 ([Section 5.2](../2511.21631.md#52-multimodal-reasoning)): MMMU, MathVista, MathVision
   - 문서 이해 ([Section 5.4](../2511.21631.md#54-text-recognition-and-document-understanding)): OCRBench, DocVQA
   - 비디오 이해 ([Section 5.9](../2511.21631.md#59-video-understanding)): Video-MME, MVBench
3. **건너뛰기**: 상세한 벤치마크별 방법론 (Appendix B)—특정 평가를 복제해야 할 때만 참조

**주요 관찰**:
- Thinking 모드는 추론 작업에서 1-8점 개선 제공 ([Table 2](../2511.21631.md#L437))
- Qwen3-VL-32B는 이미 많은 작업에서 Qwen2.5-VL-72B를 능가 ([Section 5.2](../2511.21631.md#L421))—효율적인 스케일링 보여줌
- 일부 벤치마크는 포화 상태 (90+)—예: MMBench, DocVQA—더 어려운 평가 필요성 시사

**링크**: [Section 5](../2511.21631.md#5-evaluation)

---

### Section 4.6: 인프라

**왜**: 학습 인프라 (10,000 GPU, 하이브리드 병렬화)를 설명—규모를 이해하는 데 유용하지만 기술적으로 참신하지 않음.

**핵심 사항**:
- Alibaba Cloud PAI-Lingjun AI Computing Service
- 하이브리드 병렬화: Megatron-LM 사용 TP/PP/CP/EP/ZeRO-1 DP
- 배포: vLLM (PagedAttention) 및 SGLang (구조화된 생성)

**추출할 사항**:
- 규모: 사전학습에 10,000 GPU (시간 추정 제공되지 않음)
- 병렬화 전략: 표준 Megatron-LM 설정—아키텍처적으로 참신한 것 없음
- 추론 백엔드: 처리량을 위한 vLLM, 복잡한 프롬프트를 위한 SGLang

**링크**: [Section 4.6](../2511.21631.md#46-infrastructure)

---

## ❌ 건너뛰기 (필요에 따라 참조)

### Section 3.2.1-3.2.9: 사전학습 데이터 세부사항

**왜**: 데이터 소스에 대한 매우 상세한 설명 (이미지 캡션, 지식, OCR, 그라운딩, 공간, 코드, 비디오, STEM, 에이전트)—초기 읽기에는 너무 세분화됨.

**언제 참조**:
- 사전학습을 복제하고 특정 데이터 소스 예제 필요
- 잠재적 데이터 오염 또는 벤치마크 겹침 분석
- 특정 데이터 필터링 기법에 관심 (예: 과소 표현된 개념에 대한 클러스터링)

**간단 요약**:
- 전용 필터링 파이프라인이 있는 9개 데이터 카테고리
- 재캡션 및 품질 관리에 Qwen2.5-VL 대량 사용
- 다양성 (희소 영역 식별을 위한 클러스터링) 및 품질 (규칙 기반 + 모델 기반 필터링) 강조

**링크**: [Section 3.2](../2511.21631.md#32-pre-training-data)

---

### Section 4.3: Strong-to-Weak 증류

**왜**: Qwen3 텍스트 전용 모델에서 표준 증류 파이프라인—멀티모달 참신함 없음.

**간단 요약**:
- Off-policy 증류 (교사가 응답 생성)
- On-policy 증류 (학생이 생성, 교사 로짓과 KL 발산 최소화)
- LLM 백본 파인튜닝을 위한 텍스트 전용 데이터에 집중

**언제 참조**: Qwen3-VL이 Qwen3의 강력한 텍스트 능력을 상속하는 방법에 관심이 있는 경우

**링크**: [Section 4.3](../2511.21631.md#43-strong-to-weak-distillation)

---

### Appendix B: 평가 프롬프트

**왜**: 각 벤치마크에 사용된 정확한 프롬프트—복제에만 유용, 이해에는 아님.

**언제 참조**:
- 특정 벤치마크 평가 복제
- 점수를 부풀리는 프롬프트 엔지니어링 트릭 조사
- 평가 형식 세부사항 이해 (예: 다지선다 vs 생성)

**링크**: [Appendix B](../2511.21631.md#b-evaluation)

---

## 읽기 순서 권장사항

### 빠른 이해 (30분):
1. Abstract + Introduction ([Lines 86-131](../2511.21631.md#L86-L131))
2. Section 2: 모델 아키텍처 ([Lines 133-163](../2511.21631.md#L133-L163))
3. Section 5.12: 제거 실험 ([Section 5.12](../2511.21631.md#512-ablation-study))
4. 벤치마크 결과를 위한 Table 2 훑어보기 ([Line 437](../2511.21631.md#L437))

### 심층 기술 이해 (2-3시간):
1. Abstract + Introduction
2. Section 2: 모델 아키텍처 (모든 하위 섹션)
3. Section 3.1: 학습 레시피
4. Section 4.2: Cold Start 데이터
5. Section 4.4: 강화학습
6. Section 5.12: 제거 실험
7. 선택된 벤치마크 섹션 (5.1, 5.2, 5.4, 5.9)

### 복제 (1-2일):
1. 모든 필독 + 중요 섹션
2. Section 3.2: 사전학습 데이터 (데이터 큐레이션 세부사항)
3. Section 4.3: 증류 (텍스트 능력 보존)
4. Appendix B: 평가 프롬프트 (정확한 벤치마크 설정)
5. LLM/전임자 세부사항을 위한 Qwen3 및 Qwen2.5-VL 기술 보고서 상호 참조

---

## 섹션 의존성 그래프

```
Introduction (1)
    ↓
모델 아키텍처 (2) ← 먼저 필독
    ↓
사전학습 (3)
    ├─ 학습 레시피 (3.1) ← 필독
    └─ 데이터 세부사항 (3.2.x) ← 초기에는 건너뛰기
    ↓
사후학습 (4)
    ├─ Cold Start 데이터 (4.2) ← 중요
    ├─ 증류 (4.3) ← 초기에는 건너뛰기
    ├─ RL (4.4) ← 중요
    └─ Thinking with Images (4.5) ← 중요
    ↓
평가 (5)
    ├─ 벤치마크 결과 (5.1-5.11) ← 훑어보기
    └─ 제거 실험 (5.12) ← 필독
```

**주요 통찰**: Sections 2, 3.1, 5.12 (총 ~15페이지)를 읽으면 논문 참신함의 80%를 이해할 수 있다. 나머지 섹션은 구현 세부사항, 평가 포괄성, 복제 지침을 제공한다.
