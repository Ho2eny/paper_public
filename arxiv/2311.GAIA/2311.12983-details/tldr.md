---
parent: "../2311.12983-analysis.md"
source: "../2311.12983.md"
type: detail
created: 2026-01-09
---

# GAIA: Extended TL;DR

[Back to Main Analysis](../2311.12983-analysis.md) | [Original Paper](../2311.12983.md)

---

## 한 줄 요약

GAIA는 인간에게는 개념적으로 단순하지만(92% 성공률) AI에게는 어려운(GPT-4+plugins 15%) 466개의 실세계 질문으로 구성된 범용 AI 어시스턴트 벤치마크이다.

---

## 확장 요약 (3-Paragraph Version)

### 문제 정의
기존 AI 벤치마크들은 두 가지 문제를 안고 있다. 첫째, MMLU나 GSM8k 같은 어려운 벤치마크들이 LLM의 급격한 발전과 데이터 오염으로 인해 빠르게 포화되고 있다 [Section 1](../2311.12983.md#1-introduction). 둘째, 인간에게 어려운 과제(법학, 화학 등 전문 지식)가 AI에게도 반드시 어려운 것은 아니며, 복잡한 생성 과제는 객관적 평가가 어렵다.

### 해결책: GAIA 벤치마크
GAIA는 이러한 문제를 해결하기 위해 **역발상**을 제안한다: 인간에게 쉽지만 AI에게 어려운 과제를 만들자 [Section 3.1](../2311.12983.md#31-a-convenient-yet-challenging-benchmark-for-general-ai-assistants). 이 벤치마크는 웹 브라우징, 멀티모달 이해, 코딩, 다양한 파일 형식 처리 등의 근본적 능력을 테스트하며, 정답이 단일하고 명확하여 자동화된 평가가 가능하다. 466개 질문은 3단계 난이도로 분류되며, 각 질문은 실제 AI 어시스턴트 사용 사례를 반영한다.

### 핵심 발견
GPT-4 with plugins가 가장 쉬운 Level 1에서 30.3%, 전체적으로 약 15%의 성공률을 보인 반면, 인간 평가자는 92%의 성공률을 달성했다 [Section 4](../2311.12983.md#4-llms-results-on-gaia). 이러한 극명한 격차는 현재 AI 시스템이 진정한 범용 어시스턴트가 되기까지 상당한 발전이 필요함을 시사한다. 저자들은 GAIA를 해결하는 시스템이 t-AGI(시간 제한 AGI)의 중요한 이정표가 될 것이라고 주장한다.

---

## 핵심 인사이트

1. **패러다임 전환**: "인간에게 어려운 것 = AI에게 어려운 것"이라는 기존 가정을 뒤집음
2. **Proof of Work 유사성**: 정답은 검증하기 쉽지만 도출하기 어려운 구조
3. **도구 사용의 중요성**: GPT-4 alone(9.1%) vs GPT-4+plugins(30.3%)의 차이가 도구 통합의 가치를 입증
4. **게이밍 저항성**: 단일 정답, 추론 과정 추적 가능, 인터넷에 없는 답변 설계

---

## 관련 섹션 링크

- [Introduction](../2311.12983.md#1-introduction): 벤치마크의 필요성과 동기
- [Section 3](../2311.12983.md#3-gaia): GAIA 설계 원칙과 구성
- [Section 4](../2311.12983.md#4-llms-results-on-gaia): 실험 결과
- [Section 5](../2311.12983.md#5-discussion): 논의 및 시사점
